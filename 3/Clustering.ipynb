{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create frequency dictionary with words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "frequency_stats = dict()\n",
    "\n",
    "for line in open('data/lines.txt', encoding='utf-8'):\n",
    "    words = [word.strip().lower() for word in line.strip().split()]\n",
    "    for word in words:\n",
    "        if word in frequency_stats:\n",
    "            frequency_stats[word] += 1\n",
    "        else:\n",
    "            frequency_stats[word] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stats.txt', 'w+') as file:\n",
    "    for word in sorted(frequency_stats, key=frequency_stats.get, reverse=True):\n",
    "        file.write(\"{word}: {number_of_times}\\n\".format(word=word, number_of_times=frequency_stats[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose words that seems to be just noise, nothing meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = ['logistics', 'of', 'ltd', 'ltd.', 'o.o.ul', 'ul.', 'tel', 'fax', 'sp.', 'road,', 'road'\n",
    "             'z', 'co.', 'and', 'co.,ltd', 'co', ':', 'ooo', 'as', '-', 'on', '+', 'sa', 'the', 'street',\n",
    "            'email', 'contact', 'ul', 'str', 'st',  '.', ',', '\"', '?', '!', ':', ';', '[', ']',\n",
    "             '(', ')', 'â€“', '-', '%', \"'\", '+', '/', '<', '>', 'street,']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and remove stoplist words from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for line in open('data/lines.txt'):\n",
    "    line = line.lower().split()\n",
    "    line = [word for word in line if word not in stop_list]\n",
    "    line = ' '.join(line)\n",
    "    text.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams(n, line):\n",
    "    ngrams = set()\n",
    "    for index in range(len(line) - n):\n",
    "        ngrams.add(line[index:index+n])\n",
    "    \n",
    "    return ngrams\n",
    "\n",
    "def calculate_dice_index(n, first_line, second_line):\n",
    "    first_ngrams = create_ngrams(n, first_line)\n",
    "    second_ngrams = create_ngrams(n, second_line)\n",
    "    \n",
    "    return 1 - (2*len(first_ngrams & second_ngrams) / (len(first_ngrams) + len(second_ngrams)))\n",
    "\n",
    "def create_clusters(text, n, threshold):\n",
    "    clusters = dict()\n",
    "    cluster_counter = 0\n",
    "    clusters[cluster_counter] = [0]\n",
    "    \n",
    "    for index, line in enumerate(text[1:]):\n",
    "        added_to_some_cluster = False\n",
    "        \n",
    "        print(index+1)\n",
    "        print(line)\n",
    "        for cluster in clusters:\n",
    "            should_line_be_added_to_cluster = False\n",
    "            print(cluster)\n",
    "            result = 1\n",
    "            \n",
    "            for cluster_line in clusters[cluster]:\n",
    "                print(cluster_line)\n",
    "                print(\"text[cluster_line] \" + str(text[cluster_line]))\n",
    "                print(\"line \" + line)\n",
    "                dice_index = calculate_dice_index(n, text[cluster_line], line) \n",
    "                print(dice_index)\n",
    "                                                  \n",
    "                if dice_index < threshold:\n",
    "                    should_line_be_added_to_cluster = True\n",
    "                    added_to_some_cluster = True\n",
    "            \n",
    "            if should_line_be_added_to_cluster:\n",
    "                clusters[cluster].append(index+1)\n",
    "        if not added_to_some_cluster:\n",
    "            clusters[len(clusters)] = [index+1]\n",
    "    \n",
    "    return clusters\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "ala ma\n",
      "0\n",
      "0\n",
      "text[cluster_line] ala ma kota\n",
      "line ala ma\n",
      "0.4545454545454546\n",
      "2\n",
      "kota 2\n",
      "0\n",
      "0\n",
      "text[cluster_line] ala ma kota\n",
      "line kota 2\n",
      "0.8181818181818181\n",
      "1\n",
      "text[cluster_line] ala ma\n",
      "line kota 2\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [0, 1], 1: [2]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = [\"ala ma kota\", \"ala ma\", \"kota 2\"]\n",
    "\n",
    "create_clusters(text2, 3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
